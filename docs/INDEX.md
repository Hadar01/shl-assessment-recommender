# SHL Assessment Recommender - Documentation Index

## ğŸ“š Repository Structure Overview

```
shl_recommender_starter/
â”œâ”€â”€ README.md                          # Start here - Project overview & quick start
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ pyproject.toml                     # Project configuration
â”‚
â”œâ”€â”€ shlrec/                           # Core recommendation engine
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ recommender.py                # Main orchestrator (entry point)
â”‚   â”œâ”€â”€ retrieval.py                  # Hybrid search (BM25 + semantic)
â”‚   â”œâ”€â”€ indexer.py                    # Index construction
â”‚   â”œâ”€â”€ llm_gemini.py                 # LLM integration (Gemini)
â”‚   â”œâ”€â”€ balancing.py                  # K/P test balancing
â”‚   â”œâ”€â”€ settings.py                   # Configuration management
â”‚   â””â”€â”€ utils.py                      # Utility functions
â”‚
â”œâ”€â”€ api/                              # REST API
â”‚   â””â”€â”€ main.py                       # FastAPI server (/recommend endpoint)
â”‚
â”œâ”€â”€ ui/                               # User interfaces
â”‚   â””â”€â”€ streamlit_app.py              # Interactive Streamlit dashboard
â”‚
â”œâ”€â”€ scripts/                          # Data & evaluation pipelines
â”‚   â”œâ”€â”€ build_index.py                # Build search index
â”‚   â”œâ”€â”€ scrape_catalog.py             # Scrape SHL catalog
â”‚   â”œâ”€â”€ evaluate_train.py             # Performance evaluation
â”‚   â””â”€â”€ generate_test_csv.py          # Generate predictions
â”‚
â”œâ”€â”€ data/                             # Data directory
â”‚   â”œâ”€â”€ catalog.jsonl                 # SHL assessment catalog (377 items)
â”‚   â”œâ”€â”€ Gen_AI Dataset.xlsx           # Training/evaluation set
â”‚   â”œâ”€â”€ predictions.csv               # Test set predictions
â”‚   â””â”€â”€ index/                        # Search index (BM25 + embeddings)
â”‚       â”œâ”€â”€ meta.json
â”‚       â”œâ”€â”€ bm25.pkl
â”‚       â”œâ”€â”€ embeddings.npy
â”‚       â””â”€â”€ corpus_tokens.pkl
â”‚
â”œâ”€â”€ docs/                             # Documentation (this folder)
â”‚   â”œâ”€â”€ INDEX.md                      # You are here
â”‚   â”œâ”€â”€ setup/                        # Setup & deployment
â”‚   â”œâ”€â”€ architecture/                 # System design
â”‚   â”œâ”€â”€ development/                  # Development guides
â”‚   â”œâ”€â”€ evaluation/                   # Performance & metrics
â”‚   â””â”€â”€ submission/                   # Submission materials
â”‚
â”œâ”€â”€ .env.example                      # Configuration template
â”œâ”€â”€ .gitignore                        # Git exclusions
â””â”€â”€ predictions.csv                  # Final test predictions

```

---

## ğŸš€ Quick Navigation by Task

### 1ï¸âƒ£ **Getting Started**
- **First time here?** â†’ Read [README.md](../README.md)
- **Setup instructions** â†’ See [docs/setup/QUICK_START.md](setup/QUICK_START.md)
- **Install dependencies** â†’ `pip install -r requirements.txt`

### 2ï¸âƒ£ **Understanding the System**
- **Architecture overview** â†’ [docs/architecture/SYSTEM_DESIGN.md](architecture/SYSTEM_DESIGN.md)
- **How recommendation works** â†’ [docs/architecture/RECOMMENDATION_FLOW.md](architecture/RECOMMENDATION_FLOW.md)
- **Code structure** â†’ [docs/architecture/CODE_STRUCTURE.md](architecture/CODE_STRUCTURE.md)

### 3ï¸âƒ£ **Running the System**
- **Start API server** â†’ `python -m uvicorn api.main:app --reload`
- **Start Streamlit UI** â†’ `streamlit run ui/streamlit_app.py`
- **Build index** â†’ `python -m scripts.build_index --catalog data/catalog.jsonl --index_dir data/index`
- **Evaluate performance** â†’ `python -m scripts.evaluate_train --xlsx data/Gen_AI\ Dataset.xlsx --index_dir data/index`

### 4ï¸âƒ£ **Understanding Performance**
- **Evaluation results** â†’ [docs/evaluation/METRICS.md](evaluation/METRICS.md)
- **Performance analysis** â†’ [docs/evaluation/PERFORMANCE_ANALYSIS.md](evaluation/PERFORMANCE_ANALYSIS.md)
- **Optimization history** â†’ [docs/evaluation/OPTIMIZATION_HISTORY.md](evaluation/OPTIMIZATION_HISTORY.md)

### 5ï¸âƒ£ **Development & Contributing**
- **Development guide** â†’ [docs/development/DEVELOPMENT.md](development/DEVELOPMENT.md)
- **Phase 3 experimental features** â†’ [docs/development/PHASE3_ANALYSIS.md](development/PHASE3_ANALYSIS.md)
- **Code improvements** â†’ [docs/development/IMPROVEMENTS.md](development/IMPROVEMENTS.md)

### 6ï¸âƒ£ **Submission Materials**
- **Submission checklist** â†’ [docs/submission/DELIVERABLES.md](submission/DELIVERABLES.md)
- **Verification checklist** â†’ [docs/submission/VERIFICATION.md](submission/VERIFICATION.md)
- **GitHub instructions** â†’ [docs/submission/GITHUB.md](submission/GITHUB.md)

---

## ğŸ“Š System Flow

```
User Query
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               shlrec/recommender.py (Orchestrator)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    â”œâ”€â†’ Query Preprocessing
    â”œâ”€â†’ Hybrid Search (retrieval.py)
    â”‚   â”œâ”€â†’ BM25 Search (Alpha=0.39 â†’ 39% weight)
    â”‚   â””â”€â†’ Semantic Search (1-Alpha=0.61 â†’ 61% weight)
    â”œâ”€â†’ Candidate Pool Retrieval (Top 200)
    â”œâ”€â†’ Test Type Filtering & K/P Balancing (balancing.py)
    â””â”€â†’ Final Ranking
    â†“
Recommendations (Top 10 Assessments)
```

---

## ğŸ”‘ Key Files & Their Purpose

### Core Engine
| File | Purpose | Key Functions |
|------|---------|---|
| `shlrec/recommender.py` | Main orchestrator | `recommend()` - entry point |
| `shlrec/retrieval.py` | Hybrid search | `hybrid_search()`, `bm25_search()`, `semantic_search()` |
| `shlrec/indexer.py` | Index builder | `build_index()`, `load_index()` |
| `shlrec/balancing.py` | K/P balancing | `balance_k_p_assessments()` |

### Integration & Configuration
| File | Purpose | Key Functions |
|------|---------|---|
| `shlrec/llm_gemini.py` | LLM interface | `extract_intent()`, `rerank_with_gemini()` |
| `shlrec/settings.py` | Config management | `Settings` class, env variables |
| `shlrec/utils.py` | Utilities | Helper functions |

### APIs & UIs
| File | Purpose | Key Endpoints/Features |
|------|---------|---|
| `api/main.py` | REST API | `POST /recommend` |
| `ui/streamlit_app.py` | Dashboard | Interactive recommendation UI |

### Data Pipelines
| File | Purpose | Inputs/Outputs |
|------|---------|---|
| `scripts/build_index.py` | Index building | `.jsonl` catalog â†’ Search index |
| `scripts/scrape_catalog.py` | Data collection | SHL website â†’ `.jsonl` catalog |
| `scripts/evaluate_train.py` | Performance eval | `.xlsx` test set â†’ Metrics |
| `scripts/generate_test_csv.py` | Prediction gen | Test set â†’ `predictions.csv` |

---

## ğŸ“ˆ Performance Metrics

**Current Performance:**
- **Recall@10:** 23.78%
- **MAP@10:** 16.74%
- **Configuration:** HYBRID_ALPHA=0.39, CANDIDATE_POOL=200

See [docs/evaluation/METRICS.md](evaluation/METRICS.md) for detailed breakdown.

---

## ğŸ”§ Configuration

### Environment Variables
See `.env.example` for all available settings:

```env
HYBRID_ALPHA=0.39              # 39% BM25, 61% semantic
CANDIDATE_POOL=200            # Top candidates before filtering
RERANK_WITH_GEMINI=0          # Disable LLM reranking
GEMINI_API_KEY=...            # Optional: for LLM features
INDEX_DIR=data/index          # Search index location
```

---

## ğŸ¯ Common Workflows

### Scenario 1: Adding New Assessments
1. Update `data/catalog.jsonl` with new entries
2. Rebuild index: `python -m scripts.build_index ...`
3. Test with UI: `streamlit run ui/streamlit_app.py`

### Scenario 2: Improving Performance
1. Review metrics: [docs/evaluation/METRICS.md](evaluation/METRICS.md)
2. Check optimization history: [docs/evaluation/OPTIMIZATION_HISTORY.md](evaluation/OPTIMIZATION_HISTORY.md)
3. Make changes & evaluate: `python -m scripts.evaluate_train ...`

### Scenario 3: Deploying to Production
1. Set `.env` with production values
2. Build index: `python -m scripts.build_index ...`
3. Start API: `python -m uvicorn api.main:app --reload`
4. See [docs/setup/DEPLOYMENT.md](setup/DEPLOYMENT.md)

---

## ğŸ“š Documentation Organization

### By Purpose:
- **Setup** (`docs/setup/`) - Installation, deployment, configuration
- **Architecture** (`docs/architecture/`) - System design, data flow, code structure
- **Development** (`docs/development/`) - Contributing, improvements, experimentation
- **Evaluation** (`docs/evaluation/`) - Metrics, analysis, performance tuning
- **Submission** (`docs/submission/`) - Deliverables, verification, GitHub

### By Audience:
- **End Users** â†’ Start with README.md, then `docs/setup/QUICK_START.md`
- **Developers** â†’ Check `docs/architecture/` and `docs/development/`
- **Reviewers** â†’ See `docs/submission/DELIVERABLES.md` and `docs/evaluation/METRICS.md`
- **DevOps** â†’ Read `docs/setup/DEPLOYMENT.md`

---

## ğŸš€ Next Steps

1. **New here?** Read [README.md](../README.md) first
2. **Want to run it?** Follow [docs/setup/QUICK_START.md](setup/QUICK_START.md)
3. **Need details?** Browse [docs/architecture/](architecture/)
4. **Reviewing?** Check [docs/submission/DELIVERABLES.md](submission/DELIVERABLES.md)

---

**Last Updated:** December 18, 2025  
**Version:** 1.0 - Production Ready
